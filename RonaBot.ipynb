{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtzR56JE1JS0"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la5ePCMt1hNU",
        "outputId": "2feb0374-9577-4fbe-ef33-b02ddf095e89"
      },
      "outputs": [],
      "source": [
        "#importing and reading corpus\n",
        "f=open('ronabot.txt','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug1KB2MJ21tz",
        "outputId": "1b06c87d-0221-4ce4-df09-34147efd9282"
      },
      "outputs": [],
      "source": [
        "#sentence token example\n",
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HATgaqTh2574",
        "outputId": "c489ad86-61c7-491a-af7b-72185f5119c8"
      },
      "outputs": [],
      "source": [
        "#word tokens example\n",
        "word_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuRcnHhr29M-"
      },
      "outputs": [],
      "source": [
        "#Text preprocessing\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically oriented dictionary of english included in NLTK\n",
        "stopwords = nltk.corpus.stopwords\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token, 'v') for token in tokens if token not in set(stopwords.words('english'))]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECzMfEt74Kf7"
      },
      "outputs": [],
      "source": [
        "#Defining the Greeting Function\n",
        "GREET_INPUTS = (\"hello\",\"hi\",\"greetings\",\"sup\",\"whats up\",\"hey\")\n",
        "GREET_RESPONSES = [\"hi\",\"hey\",\"*nods*\",\"hi there\",\"hello\"]\n",
        "def greet(sentence):\n",
        "\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GREET_INPUTS:\n",
        "      return random.choice(GREET_RESPONSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUmpjWUy5T4_"
      },
      "outputs": [],
      "source": [
        "#genrating responses\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jdcQH5Z5oIN"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, analyzer='word', max_features=80)\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf)==0:\n",
        "    robo1_response = robo1_response + \"I am sorry, I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response + sent_tokens[idx]\n",
        "    return robo1_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VTHSkWv7gY-",
        "outputId": "4bb6dc0f-c109-44f2-e05b-a35388975369"
      },
      "outputs": [],
      "source": [
        "#Defining conversation start and end protocols\n",
        "flag=True\n",
        "print('''RonaBot: Welcome! You can ask me anything about COVID-19 in Canada as at April 20,2022.\n",
        "To exit at any point, type bye''')\n",
        "while(flag == True):\n",
        "  user_response = input('User: ')\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response!='bye'):\n",
        "    if(user_response=='thanks' or user_response=='thank you'):\n",
        "      flag = False\n",
        "      print('RonaBot: You are welcome')\n",
        "    else:\n",
        "      if(greet(user_response)!= None):\n",
        "        print(\"RonaBot: \"+greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens = word_tokens+ nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print(\"RonaBot: \", end=\"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag=False\n",
        "    print(\"RonaBot: Goodbye! Stay Safe..\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RonaBot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
